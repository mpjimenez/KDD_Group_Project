{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.patches import Polygon\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.colors import rgb2hex\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\Sam\\\\Documents\\\\cal poly\\\\3\\\\spring\\\\cs466\\\\project\\\\KDD_Group_Project\\\\datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final = pd.read_csv(path + \"\\\\fatal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coords = pd.read_csv(path + \"\\\\city_coordinates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = np.array([x.split(\" \") for x in coords[\"Location \"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newtmp = np.array([[\" \".join(x[:-1]), x[-1]] for x in tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coords[\"city\"] = newtmp[:,0]\n",
    "coords[\"state\"] = newtmp[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finaldf = pd.merge(final, coords, how = \"left\", on = [\"city\", \"state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popdens = {final.iloc[x][\"state\"]: final.iloc[x][\"state_pop\"] for x in range(len(final))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = Counter(finaldf.state)\n",
    "for i in counts:\n",
    "    counts[i] = counts[i] / popdens[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "mapfile = \"C:\\\\Users\\\\Sam\\\\Desktop\\\\Research - Crow White\\\\data\\\\USA_adm_shp\"\n",
    "colors = {}\n",
    "ccc = []\n",
    "statenames = []\n",
    "indices = {}\n",
    "fig = plt.figure(figsize = (20,15))\n",
    "ax = fig.add_subplot(111)\n",
    "m = Basemap(llcrnrlon=-119,llcrnrlat=22,urcrnrlon=-64,urcrnrlat=49,\n",
    "        projection='lcc',lat_1=33,lat_2=45,lon_0=-95)\n",
    "m.ax = ax\n",
    "m.readshapefile(mapfile + '\\\\USA_adm1', name='states', drawbounds=True)\n",
    "\n",
    "cmap = plt.cm.viridis\n",
    "vmin = min(counts.values())\n",
    "vmax = max(counts.values())\n",
    "for shapedict in range(len(m.states_info)):\n",
    "    statename = m.states_info[shapedict]['HASC_1'].split(\".\")[-1]\n",
    "    count = counts[statename]\n",
    "    #if m.states_info[shapedict][\"NAME_1\"] in colors:\n",
    "    #    continue\n",
    "    #else:\n",
    "        #print(1 - np.sqrt((count - vmin)/(vmax-vmin)))\n",
    "    colors[m.states_info[shapedict][\"NAME_1\"]] = cmap(np.sqrt((count - vmin)/(vmax-vmin)))[:3]\n",
    "    statenames.append(m.states_info[shapedict][\"NAME_1\"])\n",
    "    indices[shapedict] = m.states_info[shapedict][\"NAME_1\"]\n",
    "    ccc.append(count)\n",
    "    \n",
    "\n",
    "m.drawcoastlines()\n",
    "m.drawcountries()\n",
    "m.drawmapboundary(fill_color='#99ffff')\n",
    "m.fillcontinents(color='#cc9966', lake_color='#99ffff');\n",
    "patches = []\n",
    "\n",
    "for nshape, seg in enumerate(m.states):\n",
    "    \n",
    "    #if nshape in indices:\n",
    "    color = rgb2hex(colors[indices[nshape]])\n",
    "        #print(color)\n",
    "    poly = Polygon(seg, facecolor = color, edgecolor = color)\n",
    "    ax.add_patch(poly)\n",
    "    patches.append(poly)\n",
    "    \n",
    "\n",
    "p = PatchCollection(patches, cmap=plt.cm.viridis)\n",
    "p.set_array(np.array(ccc))\n",
    "cb = fig.colorbar(p, ax=ax)\n",
    "\n",
    "#plt.show()\n",
    "plt.savefig(\"statedistplot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Sam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "clean = final[[\"manner_of_death\", \"armed\", \"age\", \"gender\", \"race\", \"state\", \"signs_of_mental_illness\", \"threat_level\", \"flee\", \"body_camera\", \"state_pop\"]]\n",
    "\n",
    "clean[\"signs_of_mental_illness\"] = [1 if clean.iloc[x][\"signs_of_mental_illness\"] == True else 0 for x in range(len(clean))]\n",
    "clean[\"body_camera\"] = [1 if clean.iloc[x][\"body_camera\"] == True else 0 for x in range(len(clean))]\n",
    "\n",
    "clean = clean.dropna()\n",
    "\n",
    "np.random.seed(0)\n",
    "clean = clean.sample(frac = 1)\n",
    "labels = clean[\"race\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dumm = pd.get_dummies(clean[[x for x in clean.columns if x != \"race\"]])\n",
    "labels = pd.get_dummies(labels)\n",
    "input_size = len(dumm.columns)\n",
    "alld = dumm.values\n",
    "alllabels = labels.values\n",
    "xtrain, ytrain = alld[:int(.8 * len(alld)),], alllabels[:int(.8 * len(alld)),]\n",
    "xtest, ytest = alld[int(.8 * len(alld)):,], alllabels[int(.8* len(alld)):,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newx = []\n",
    "newy = []\n",
    "for i in range(len(xtrain)):\n",
    "    if np.argmax(ytrain[i]) != 5:\n",
    "        newx.append(xtrain[i])\n",
    "        newx.append(xtrain[i])\n",
    "        newy.append(ytrain[i])\n",
    "        newy.append(ytrain[i])\n",
    "    else:\n",
    "        newx.append(xtrain[i])\n",
    "        newy.append(ytrain[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = np.array(newx)\n",
    "ytrain = np.array(newy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(8, input_shape = (input_size,), kernel_regularizer=regularizers.l2(.01), activation = \"sigmoid\"))\n",
    "nn.add(layers.Dropout(.2))\n",
    "nn.add(BatchNormalization())\n",
    "nn.add(layers.Dense(8, activation = \"sigmoid\", kernel_regularizer=regularizers.l2(.01)))\n",
    "nn.add(layers.Dense(6, activation = \"softmax\"))\n",
    "\n",
    "nn.compile(\n",
    "    optimizer=\"rmsprop\",             # Improved backprop algorithm\n",
    "    loss='categorical_crossentropy', # \"Misprediction\" measure\n",
    "    metrics=['accuracy']             # Report CCE value as we train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 1136      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 54        \n",
      "=================================================================\n",
      "Total params: 1,294\n",
      "Trainable params: 1,278\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3593 samples, validate on 605 samples\n",
      "Epoch 1/20\n",
      "3593/3593 [==============================] - 1s 150us/step - loss: 2.2007 - acc: 0.0145 - val_loss: 2.0992 - val_acc: 0.0149\n",
      "Epoch 2/20\n",
      "3593/3593 [==============================] - 0s 27us/step - loss: 1.8675 - acc: 0.1222 - val_loss: 1.7943 - val_acc: 0.2579\n",
      "Epoch 3/20\n",
      "3593/3593 [==============================] - 0s 23us/step - loss: 1.6568 - acc: 0.3087 - val_loss: 1.6056 - val_acc: 0.2579\n",
      "Epoch 4/20\n",
      "3593/3593 [==============================] - 0s 22us/step - loss: 1.5217 - acc: 0.3437 - val_loss: 1.4702 - val_acc: 0.2579\n",
      "Epoch 5/20\n",
      "3593/3593 [==============================] - 0s 20us/step - loss: 1.4363 - acc: 0.3440 - val_loss: 1.4169 - val_acc: 0.2579\n",
      "Epoch 6/20\n",
      "3593/3593 [==============================] - 0s 21us/step - loss: 1.3846 - acc: 0.3421 - val_loss: 1.3023 - val_acc: 0.2579\n",
      "Epoch 7/20\n",
      "3593/3593 [==============================] - 0s 22us/step - loss: 1.3577 - acc: 0.3365 - val_loss: 1.2510 - val_acc: 0.5322\n",
      "Epoch 8/20\n",
      "3593/3593 [==============================] - 0s 22us/step - loss: 1.3394 - acc: 0.3493 - val_loss: 1.2463 - val_acc: 0.5322\n",
      "Epoch 9/20\n",
      "3593/3593 [==============================] - 0s 23us/step - loss: 1.3309 - acc: 0.3443 - val_loss: 1.2432 - val_acc: 0.5322\n",
      "Epoch 10/20\n",
      "3593/3593 [==============================] - 0s 21us/step - loss: 1.3236 - acc: 0.3479 - val_loss: 1.2446 - val_acc: 0.5322\n",
      "Epoch 11/20\n",
      "3593/3593 [==============================] - 0s 20us/step - loss: 1.3202 - acc: 0.3345 - val_loss: 1.2579 - val_acc: 0.2579\n",
      "Epoch 12/20\n",
      "3593/3593 [==============================] - 0s 20us/step - loss: 1.3170 - acc: 0.3482 - val_loss: 1.2582 - val_acc: 0.2579\n",
      "Epoch 13/20\n",
      "3593/3593 [==============================] - 0s 21us/step - loss: 1.3157 - acc: 0.3501 - val_loss: 1.2503 - val_acc: 0.2579\n",
      "Epoch 14/20\n",
      "3593/3593 [==============================] - 0s 21us/step - loss: 1.3149 - acc: 0.3284 - val_loss: 1.2365 - val_acc: 0.5322\n",
      "Epoch 15/20\n",
      "3593/3593 [==============================] - 0s 22us/step - loss: 1.3143 - acc: 0.3370 - val_loss: 1.2435 - val_acc: 0.5322\n",
      "Epoch 16/20\n",
      "3593/3593 [==============================] - 0s 21us/step - loss: 1.3139 - acc: 0.3501 - val_loss: 1.2628 - val_acc: 0.2579\n",
      "Epoch 17/20\n",
      "3593/3593 [==============================] - 0s 21us/step - loss: 1.3133 - acc: 0.3468 - val_loss: 1.2405 - val_acc: 0.5322\n",
      "Epoch 18/20\n",
      "3593/3593 [==============================] - 0s 22us/step - loss: 1.3132 - acc: 0.3440 - val_loss: 1.2456 - val_acc: 0.5322\n",
      "Epoch 19/20\n",
      "3593/3593 [==============================] - 0s 21us/step - loss: 1.3127 - acc: 0.3409 - val_loss: 1.2453 - val_acc: 0.5322\n",
      "Epoch 20/20\n",
      "3593/3593 [==============================] - 0s 21us/step - loss: 1.3128 - acc: 0.3351 - val_loss: 1.2515 - val_acc: 0.2579\n"
     ]
    }
   ],
   "source": [
    "hst = nn.fit(xtrain, ytrain, epochs = 20, batch_size = 64,\n",
    " validation_data = (xtest, ytest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

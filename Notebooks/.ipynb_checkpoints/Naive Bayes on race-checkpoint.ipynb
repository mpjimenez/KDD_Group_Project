{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getClassProbability(labels, classId,nClasses):\n",
    "    return sum([1 for i in labels if i == classId]) / len(labels)\n",
    "\n",
    "def getNBEstimate(data, labels, classLabel, attId, attValue, nValues):\n",
    "    indices, = np.where(labels == classLabel)\n",
    "    subset = data[indices,attId]\n",
    "    return sum([1 for i in subset if i == attValue]) / len(subset)\n",
    "\n",
    "def estimateNBModel(data, labels, nAttributes, attributeRanges, nClasses):\n",
    "    ## Naive Bayes Model consists of two types of estimators\n",
    "    ## First, we estimate the probability of seeing an object from a specific class\n",
    "\n",
    "    classProbabilities = [getClassProbability(labels,l, nClasses) for l in range(nClasses)]\n",
    "    #print(classProbabilities, nClasses)\n",
    "    \n",
    "    ## now we estimate the probabilities of seeing a specific value of a specific attribute in\n",
    "    ## a data point from a given class\n",
    "    \n",
    "    ## for each class create the appropriate estimates\n",
    "    model = []                  # model is the list of estimates for all classes\n",
    "    for i in range(nClasses):   # for each class\n",
    "        ## for each attribute\n",
    "        classDistr = []         # classDistr is the collection of estimates for one class\n",
    "        for j in range(nAttributes):\n",
    "            estimates = []                    # estimates is a distribution of estimates for a single attribute\n",
    "            for k in range(attributeRanges[j]):\n",
    "                est = getNBEstimate(data, labels, i,j,k, attributeRanges[j])\n",
    "\n",
    "                estimates.append(est)\n",
    "            classDistr.append(estimates)\n",
    "        model.append(classDistr)\n",
    "    \n",
    "    return classProbabilities, model\n",
    "    \n",
    "\n",
    "def predictNBClass(point, classProb, classModel):\n",
    "    ans = 1\n",
    "    for i in range(len(classModel)):\n",
    "        ans *= classModel[i][int(point[i])]\n",
    "    return ans * classProb\n",
    "\n",
    "def predictNB(point, classProbabilities, model,nClasses):\n",
    "    \n",
    "    predictions= np.array([predictNBClass(point, classProbabilities[i],model[i]) for i in range(nClasses)])\n",
    "    \n",
    "    predictedClass = np.argmax(predictions)\n",
    "    return predictedClass\n",
    "\n",
    "def predictNBLabels(data, classProbabilities, model, nClasses):\n",
    "    predicted = [predictNB(point, classProbabilities, model, nClasses) for point in data]\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad = [\"Unnamed: 0\", \"id\", \"name\", \"Ethnicity\", \"date\", \"city\"]\n",
    "path = \"C:\\\\Users\\\\Sam\\\\Documents\\\\cal poly\\\\3\\\\spring\\\\cs466\\\\project\\\\KDD_Group_Project\\\\datasets\\\\fatal.csv\"\n",
    "rawData = pd.read_csv(path)\n",
    "rawData = rawData[[x for x in rawData.columns if x not in bad]]\n",
    "rawData = rawData.dropna()\n",
    "data = rawData[[x for x in rawData if x != \"race\"]].values\n",
    "for i in range(data.shape[1]):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(data[:,i])\n",
    "    data[:,i] = le.transform(data[:,i]) \n",
    "nAttributes = data.shape[1] - 1\n",
    "labels = rawData[\"race\"].values\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels)\n",
    "labels = le.transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let us compute how many unique values each attribute has.\n",
    "### all attributes have values 0,1,.., k-1 where k is the number of unique values for that attribute.\n",
    "\n",
    "attributeRanges= [np.unique(data[:,i]).shape[0] for i in range(nAttributes)]\n",
    "\n",
    "## number of classes\n",
    "\n",
    "nClasses = np.unique(labels).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, m = estimateNBModel(data ,labels, nAttributes, attributeRanges, nClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predictNBLabels(data, d, m, nClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "80 - 20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "indices = list(range(len(data)))\n",
    "np.random.shuffle(indices)\n",
    "diff = np.array(list(set(list(range(len(data)))).difference(indices[:int(len(data) * 0.8)])))\n",
    "X_train, y_train, X_test, y_test = data[indices,:], labels[indices], data[diff,:], labels[diff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attributeRanges= [np.unique(X_train[:,i]).shape[0] for i in range(nAttributes)]\n",
    "nClasses = np.unique(y_train).shape[0]\n",
    "d, m = estimateNBModel(X_train, y_train, nAttributes, attributeRanges, nClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_train = predictNBLabels(X_train, d, m, nClasses) \n",
    "predicted_test = predictNBLabels(X_test, d, m, nClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train\n",
      "0.6399735274652548\n",
      "\n",
      "Accuracy on test\n",
      "0.6760330578512397\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on train\")\n",
    "print(sum([1 for i in range(len(y_train)) if y_train[i] == predicted_train[i]]) / len(y_train))\n",
    "print()\n",
    "print(\"Accuracy on test\")\n",
    "print(sum([1 for i in range(len(y_test)) if y_test[i] == predicted_test[i]]) / len(y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
